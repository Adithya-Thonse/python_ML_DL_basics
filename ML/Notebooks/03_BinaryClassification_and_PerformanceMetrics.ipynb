{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ps9llghv8jX1"},"source":["# Binary Classification and Performance Metrics"]},{"cell_type":"markdown","metadata":{"id":"QeP1PAXf8jYD"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"AkwaW3k58jYG"},"source":["At the end of the experiment, you will be able to:\n","\n","* learn about Classification tasks in Machine learning\n","* perform Logistic Regression, Softmax Regression\n","* learn the appropriate performance metrics according to use case\n","* have an understanding of Decision Boundaries"]},{"cell_type":"markdown","metadata":{"id":"HzIWfoFc-mis"},"source":["## Information"]},{"cell_type":"markdown","metadata":{"id":"1KfDhYd1yUIx"},"source":["### Classification"]},{"cell_type":"markdown","metadata":{"id":"q-QzRVapVOow"},"source":["**Classification** refers to a predictive modeling problem where a class label is predicted for a given example of input data.\n","\n","**Examples include:**\n","\n","* Email spam detection (spam or not).\n","* Churn prediction (churn or not).\n","* Conversion prediction (buy or not).\n","\n","**Binary classification** refers to those classification tasks that have two class labels.\n","\n","**Logistic Regression** is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). "]},{"cell_type":"markdown","metadata":{"id":"4zU4iSDHpQMB"},"source":["### Implementing Binary Classification with Logistic Regression "]},{"cell_type":"markdown","metadata":{"id":"mg_NkkELpZKB"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"ScK34HRop_Uf"},"source":["In this example, we will be using \"Social_Network_Ads\" dataset. \n","\n","The variable descriptions are as follows:\n","\n","* Age\n","* EstimatedSalary\n","\n","The target feature is:\n","* Purchased\n","\n","**Problem Statement:** To predict if a person will purchase an item based on age and estimated salary. "]},{"cell_type":"markdown","metadata":{"id":"ZWv5Dh4iO3Pj"},"source":["### Importing required packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ljIHCqCO3mk"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"markdown","metadata":{"id":"6x4tygU7rw0u"},"source":["#### Importing the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_14Ruksx4zx"},"outputs":[],"source":["df = pd.read_csv('https://raw.githubusercontent.com/Adithya-Thonse/python_ML_DL_basics/main/ML/Datasets/Social_Network_Ads.csv')\n","X = df.iloc[:, 1].values # estimated salary\n","y = df.iloc[:, -1].values\n","X = X.reshape(-1, 1)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"nz_y_tzzrxAZ"},"source":["#### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwmIhomc-igk"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8j-ECM1T-i2p"},"outputs":[],"source":["print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EyuA7_JzSN5-"},"outputs":[],"source":["print(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lcizce69SRPe"},"outputs":[],"source":["print(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00b_DUmXSRYl"},"outputs":[],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{"id":"ppSxsQ6pQbjO"},"source":["#### Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sCFtgPISPYbU"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7Qf5eY1SfVn"},"outputs":[],"source":["print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUrZNVyGSffd"},"outputs":[],"source":["print(X_test)"]},{"cell_type":"markdown","metadata":{"id":"CZqNg1ErQpt_"},"source":["#### Training the Logistic Regression model on the Training set\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmowAS_ePasE"},"outputs":[],"source":["classifier = LogisticRegression(random_state = 0)\n","classifier.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"75AUfSTKSvFe"},"source":["#### Predicting a new test instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJQOOQpXQ2-m"},"outputs":[],"source":["print(classifier.predict(sc.transform([[87000]])))"]},{"cell_type":"markdown","metadata":{"id":"6dLORN2ZSytH"},"source":["#### Predicting the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvKLpe0oSy4b"},"outputs":[],"source":["y_pred = classifier.predict(X_test)\n","print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"]},{"cell_type":"markdown","metadata":{"id":"xRZhKV_8hosC"},"source":["### Model Evaluation "]},{"cell_type":"markdown","metadata":{"id":"7gq0o0s1hrEr"},"source":["To evaluate the performance of a classification model, the following metrics are used:\n","\n","* Confusion matrix\n","  * Accuracy\n","  * Precision\n","  * Recall\n","  * F1-Score\n","* ROC curve\n","* AUROC"]},{"cell_type":"markdown","metadata":{"id":"erCaVXheUca3"},"source":["#### Confusion Matrix"]},{"cell_type":"markdown","metadata":{"id":"d0spQOwVdl6r"},"source":["* **Confusion matrix:**  is a table that is used to describe the performance of a classification model on a set of test data for which the true values are known. \n","\n","  * **true positive** for correctly predicted event values.\n","  * **false positive** for incorrectly predicted event values.\n","  * **true negative** for correctly predicted no-event values.\n","  * **false negative** for incorrectly predicted no-event values.\n","* **Accuracy:** it is the ratio of the number of correct predictions to the total number of input samples.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4J9t7uyUbmX"},"outputs":[],"source":["# Creating a confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"ghMYzkSFtbix"},"source":["This Confusion Matrix tells us that there were 81 correct predictions and 19 incorrect ones.\n","\n","* True Positive: 15\n","* True Negative: 66\n","* False Positive: 2\n","* False Negative: 17"]},{"cell_type":"markdown","metadata":{"id":"JnKMEUwPiER0"},"source":["#### Precision-Recall Metrics"]},{"cell_type":"markdown","metadata":{"id":"AZ_xgAFUiEeq"},"source":["* **Precision:** summarizes the fraction of examples assigned the positive class that belongs to the positive class.\n","\n","    Precision = $\\mathbf{\\frac{TruePositive}{TruePositive + FalsePositive}}$\n","\n","* **Recall:** summarizes how well the positive class was predicted and is the same calculation as sensitivity.\n","\n","   Recall = $\\mathbf{\\frac{TruePositive}{TruePositive + FalseNegative}}$\n","\n","* **F1-score:** precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score or the F-measure.\n","  \n","   F1-score = $\\mathbf{\\frac{2*Precision*Recall}{Precision+Recall}}$"]},{"cell_type":"markdown","metadata":{"id":"fV0iHWlKbU5l"},"source":["##### Plotting precision-recall curve using sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"btDWhBYCDsf2"},"outputs":[],"source":["# Use sklearn to plot precision-recall curves\n","\n","from sklearn.metrics import plot_precision_recall_curve\n","\n","plot_precision_recall_curve(classifier, X_test, y_test, name = 'Logistic Regression')"]},{"cell_type":"markdown","metadata":{"id":"4qE9UERaaM8W"},"source":["The above diagram shows the blue line as precision-recall curve."]},{"cell_type":"markdown","metadata":{"id":"Oi0Hm4JGiYPk"},"source":["### ROC-AUC curve"]},{"cell_type":"markdown","metadata":{"id":"nyOwoo7snM4u"},"source":["A ROC curve is a diagnostic plot for summarizing the behavior of a model by calculating the false positive rate and true positive rate for a set of predictions by the model under different thresholds.\n","\n","Area Under Curve (AUC) is one of the most widely used metrics for evaluation. It is used for binary classification problems.\n","\n","AUC has a range of [0, 1]. The greater the value, the better is the performance of our model."]},{"cell_type":"markdown","metadata":{"id":"RmcWOD9UbCFP"},"source":["#### Plotting the ROC-AUC curve for Logistic Regression algorithm using matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7N2-3HhtFQVm"},"outputs":[],"source":["# roc_curve() computes the ROC for the classifier and returns the FPR, TPR, and threshold values\n","from sklearn.metrics import roc_curve\n","\n","classifier.fit(X_train, y_train)\n","pred_prob1 = classifier.predict_proba(X_test)\n","\n","# roc curve for models\n","fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n","\n","\n","# roc curve for tpr = fpr \n","random_probs = [0 for i in range(len(y_test))]\n","p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGwFRT2bE5kq"},"outputs":[],"source":["plt.style.use('seaborn')\n","\n","# plot roc curves\n","plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\n","\n","plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n","# title\n","plt.title('ROC curve')\n","# x label\n","plt.xlabel('False Positive Rate')\n","# y label\n","plt.ylabel('True Positive rate')\n","\n","plt.legend(loc='best')\n","plt.savefig('ROC',dpi=300)\n","plt.show();"]},{"cell_type":"markdown","metadata":{"id":"vYmER6qRtzz1"},"source":["The above diagram shows:\n","\n","ROC curve: is the orange dotted line\n","\n","AUROC: is the area under the orange dotted line\n","\n","The blue dotted line is the reference line."]},{"cell_type":"markdown","metadata":{"id":"p0biP4B7XfVi"},"source":["Please refer to the given [link](https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b) for further information on Performance metrics and [ROC-AUC curve](https://medium.com/greyatom/lets-learn-about-auc-roc-curve-4a94b4d88152)"]},{"cell_type":"markdown","metadata":{"id":"ZV4AqMlfy_az"},"source":["### Example: Predicting Diabetes with Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"GLcNsXLtIFQe"},"source":["Let us now apply the above learnings to perform a logistic regression using a 'UCI PIMA Indian Diabetes' dataset.\n","\n"," * Fit the model\n"," * Do the prediction\n"," * Plot the ROC-AUC curve for the Logistic Regression algorithm\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RLe2mZvl9gm8"},"source":["#### Dataset"]},{"cell_type":"markdown","metadata":{"id":"88C2CvR63Luc"},"source":["In this example, we will be using the \"UCI PIMA Indian Diabetes\" dataset.\n","\n","The datasets consist of several medical predictor variables and one target variable, Outcome. Predictor variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n","\n","The variable descriptions are as follows:\n","\n","* Pregnancies: Number of Pregnancies\n","* Glucose: Plasma glucose concentration over 2 hours in an oral glucose tolerance test\n","* Blood pressure: Diastolic blood pressure (mm Hg)\n","* SkinThickness: Triceps skinfold thickness (mm)\n","* Insulin: 2-Hour serum insulin (mu U/ml)\n","* BMI: Body mass index (weight in kg/(height in m)2)\n","* DiabetesPedigreeFunction: Diabetes pedigree function (a function which scores likelihood of diabetes based on family history)\n","* Age: Age (years)\n","* Outcome: Class variable (0 if non-diabetic, 1 if diabetic)\n","\n","Problem statement:\n","\n","We will be using this dataset to predict if a person has diabetes or not using the medical attributes provided."]},{"cell_type":"markdown","metadata":{"id":"bragT22u9dFV"},"source":["#### Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygezgrUE3L9I"},"outputs":[],"source":["DF = pd.read_csv('https://raw.githubusercontent.com/Adithya-Thonse/python_ML_DL_basics/main/ML/Datasets/diabetes.csv')\n","print(DF.head())"]},{"cell_type":"markdown","metadata":{"id":"qrnSNpIK9nMs"},"source":["#### Finding if there are any null values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_Xk1F_O8JZD"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"EAHBKXc63MGH"},"source":["#### Training our model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nONFn5s7BSZo"},"outputs":[],"source":["# Separating the data into independent and dependent variables\n","\n","# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"ohpa54Ey3MV0"},"source":["#### Splitting the data into training and testing data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QhLdN-k-3Mdu"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"_RQF--gm3MmN"},"source":["#### Training the Logistic Regression model on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhK7n28I3My_"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"9_WlbEhI3M8A"},"source":["#### Training/Fitting the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhjpnE2a3NES"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"b_nOuS5w3NL5"},"source":["#### Making Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSJrzGgn3NT2"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"iC26I6QlCV2X"},"source":["#### Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--ycunMgCWCr"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"Yhq0Qh13zAob"},"source":["#### Plotting the ROC curve for Logistic Regression algorithm using matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAGVagUZIsbt"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"s0zX9rflZ95t"},"source":["###  Softmax Regression"]},{"cell_type":"markdown","metadata":{"id":"Vd4f0fdcrwQt"},"source":["The **Softmax regression** is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1.\n","\n","It is also called **multinomial logistic regression.**"]},{"cell_type":"markdown","metadata":{"id":"8pzGTIwxfs1T"},"source":["Performing Softmax Regression on the above dataset \"Social_Network_Ads\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6sz_oUvO_ni"},"outputs":[],"source":["X = df.iloc[:, :-1].values # considering age,estimated salary\n","y = df.iloc[:, -1].values\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"fcojjpjNaHt0"},"source":["#### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlbU7oisaHt1"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"ktJUEhjQaaZM"},"source":["#### Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKpju6jeWWps"},"outputs":[],"source":["sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"EW3_xn-zWWpu"},"source":["#### Training the Softmax Regression model on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_FJ6vU1WWpv"},"outputs":[],"source":["softmax_reg = LogisticRegression(multi_class='multinomial', # switch to Softmax Regression\n","                                     solver='lbfgs', # handle multinomial loss, L2 penalty\n","                                     C=10)\n","softmax_reg.fit(X, y)\n"]},{"cell_type":"markdown","metadata":{"id":"_DLVGNOHWWpv"},"source":["#### Predicting a new result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_gz1YF1fbY9"},"outputs":[],"source":["softmax_reg.predict(sc.transform([[30,87000]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4Gajh2DXNj2"},"outputs":[],"source":["softmax_reg.predict_proba(sc.transform([[30,87000]]))"]},{"cell_type":"markdown","metadata":{"id":"2AS_oGgsTWg8"},"source":["### Decision Boundary"]},{"cell_type":"markdown","metadata":{"id":"Mi44DjJUTgvl"},"source":["In classification problems with two or more classes, a decision boundary is a hypersurface that separates the underlying vector space into sets, one for each class."]},{"cell_type":"markdown","metadata":{"id":"NTfA1CGIT3Av"},"source":["#### Creating Dummy Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6Ncu968Evs0"},"outputs":[],"source":["from sklearn.datasets import make_classification\n","X, y = make_classification(n_samples=200, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=1)"]},{"cell_type":"markdown","metadata":{"id":"Pb4YBLrgVYh-"},"source":["#### Creating Decision Boundary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7ToIkZ-Svu-"},"outputs":[],"source":["import matplotlib.gridspec as gridspec\n","from mlxtend.plotting import plot_decision_regions\n","gs = gridspec.GridSpec(3, 2)\n","\n","fig = plt.figure(figsize=(14,10))\n","\n","label = 'Logistic Regression'\n","clf = LogisticRegression()\n","clf.fit(X, y)\n","\n","fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n","plt.title(label)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"QG24Kk9HheWP"},"source":["### Reference"]},{"cell_type":"markdown","metadata":{"id":"_EYRfyTshjEj"},"source":["https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f"]},{"cell_type":"markdown","metadata":{"id":"q4b7UWS0P9LA"},"source":["### Theory Questions"]},{"cell_type":"markdown","metadata":{"id":"vfrFcYBQRZZs"},"source":["1. Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n","\n","  Both Mini-batch and Stochastic gradient descent are not guaranteed to minimize the cost function after each step because they both have a degree of randomness built into them. Mini-bath randomly chooses which training examples to perform gradient descent on while Stochastic randomly chooses a single example. A better option is to save the model at regular intervals. When the model has not improved for a long time you can revert to the saved models."]},{"cell_type":"markdown","metadata":{"id":"xuEk-lSwQFB7"},"source":["2. Can Gradient Descent get stuck in a local minimum when training a Logistic Regression model?\n","\n","  Gradient descent produces a convex-shaped graph that only has one global optimum. Therefore, it cannot get stuck in a local minimum."]},{"cell_type":"markdown","metadata":{"id":"MBD2xCOIQFFj"},"source":["3. Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n","\n","  No. The issue is that stochastic gradient descent and mini-batch gradient descent have randomness built into them. This means that they can find their way to nearby the global optimum, but they generally don't converge. One way to help them converge is to gradually reduce the learning rate hyperparameter."]},{"cell_type":"markdown","metadata":{"id":"kjh_NvoqQFI-"},"source":["4. Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime, should you implement two Logistic Regression classifiers or one Softmax Regression classifier?\n","\n","  Softmax regression does not handle multiple output classes (i.e. [indoor, daytime]). So you'll need to use two logistic regression classifiers.\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"M2_AST_03_BinaryClassification_and_PerformanceMetrics_C.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
